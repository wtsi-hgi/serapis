Serapis
===========
Serapis is a system for archiving large genetic datasets together with metadata in a long-term storage system and facilitating the search of the entire archive based on different metadata attributes. The metadata appears within the system in the form of key-value pairs and consists of predefined attributes specific to the type of data being archived (e.g. sample id, study name, associated publication, etc). Though it is possible to use Serapis as a general purpose system, the tool has been tailored to genetics, with built-in support for genetic file formats such as BAM and VCF. It has the ability to automatically collect metadata from within these types of files, by querying external resources, or via manual entry by users. In addition to this, the system also enforces access control restrictions, which is an essential feature in the context of non-public human genetics datasets.

## Implementation details
In the configuration in use at the Sanger Institute, Serapis is accessible via a RESTful web interface and it uses the iRODS system(http://irods.org/) for backend storage. In order to perform the above described functionality, Serapis is executing all the work associated with data submission in an asynchronous, distributed way using Celery for the task management system(http://www.celeryproject.org/). The setup consists of a master process running on one machine and several workers usually running on different machines (on Sanger Institute's cluster) which are listening to certain task-queues where tasks are being sent by the master for the workers to execute. The tasks consist of: uploading a file to iRODS, gathering metadata for the file, checksumming a file, etc. When a user wants to archive a dataset, he has to make a POST request to Serapis via its RESTful interface. When the master receives a POST request, it saved the details within the request to the temporary database, and it further creates tasks corresponding to each file in the dataset and queues them for processing. Each task is executed by a worker, which reports back its success/failure of the task to the master, and the master stores all the details corresponding to a file's archival into a temporary database(MongoDB), until all the processing is finished and the file is ready for the final submission to iRODS. Each file's archiving is done in 2 steps: first the file is uploaded to a staging area and stored there until all the metadata is gathered and all the processing is finished. In the second stage if there is enough metadata for the file to be archived, then the file is moved into the permanent location, the metadata is attached to the file and the corresponding access permissions are set on it.

Please note that this system is a work in progress and that it relies on a setup specific to Sanger Institute, involving the presence of iRODS and SequencescapeDB (where metadata is fetched from), and assumes that the file formats archived are either BAM or VCF.
