Serapis
===========
Serapis is a system for archiving large genetic datasets together with metadata in a long-term storage system and facilitating the search of the entire archive based on different metadata attributes. The metadata appears within the system in the form of key-value pairs and consists of predefine attributes specific to the type of data archived (e.g. type of data - whole genome/exome/variation data, sample id, associated publication, etc). Though it is possible to use Serapis as a general purpose system, the tool has been tailored to genetics, with built-in support for genetic file formats such as BAM and VCF. It has the ability to automatically collect metadata from within these types of files, by querying external resources, or via manual entry by users. In addition to this, the system also enforces access control restrictions, which is essential in the context of non-public human genetics datasets. In the configuration in use at the Sanger Institute, Serapis uses the iRODS system(http://irods.org/) for backing storage and performs all the work associated with data submission in a distributed way on the Sanger cluster. It is implemented using a distributed task management system (Celery - http://www.celeryproject.org/), metadata is assembled temporarily in a NoSQL database(MongoDB) before it is permanently archived, and the submission system is accessible via a RESTful web interface.


## Implementation details
In order to perform the above described functionality, Serapis is working in an asynchronous way: there is a master process running on one machine and several workers usually running on different machines (on a cluster) which are listening to certain queues where tasks are being sent by the master for the workers to execute. The tasks consist of: uploading a file to iRODS, gathering metadata for the file, etc. When a user wants to archive a dataset, he has to make a POST request to Serapis via its RESTful interface. When the master receives a POST request, it saved the details within the request to the temporary database, and it further creates tasks corresponding to each file and queues them for processing. Each task reports back its success/failure to the master, and the master stores all the details corresponding to a file's archival into a temporary database(MongoDB), until all the processing is finished and the file is ready for the final submission to iRODS. Each file's archiving is done in 2 steps: first the file is uploaded to a staging area until all the metadata is gathered and all the processing is finished. In the second stage if there is enough metadata for the file to be archived, then the file is moved into the permanent location, the metadata is added to it there and the corresponding access permissions are set on it.

Please note that this system is a work in progress and that it relies on a setup specific to Sanger Institute, involving the presence of iRODS and SequencescapeDB (where metadata is fetched from), and assumes that the file formats archived are either BAM or VCF.
